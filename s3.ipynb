{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b1dd9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.4.2-cp310-cp310-win_amd64.whl (10.6 MB)\n",
      "     ---------------------------------------- 10.6/10.6 MB 9.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\wequalwo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\wequalwo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\wequalwo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.22.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\wequalwo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-1.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cfd443b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 5.6 MB/s eta 0:00:00\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "     -------------------------------------- 307.0/307.0 KB 6.3 MB/s eta 0:00:00\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2022.4.24-cp310-cp310-win_amd64.whl (262 kB)\n",
      "     ------------------------------------- 262.0/262.0 KB 16.8 MB/s eta 0:00:00\n",
      "Collecting click\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "     ---------------------------------------- 96.6/96.6 KB 5.4 MB/s eta 0:00:00\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.4/78.4 KB 4.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\wequalwo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Installing collected packages: tqdm, regex, joblib, click, nltk\n",
      "Successfully installed click-8.1.3 joblib-1.1.0 nltk-3.7 regex-2022.4.24 tqdm-4.64.0\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a89b9570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.0.2-cp310-cp310-win_amd64.whl (7.2 MB)\n",
      "     ---------------------------------------- 7.2/7.2 MB 4.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\wequalwo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.22.3)\n",
      "Collecting scipy>=1.1.0\n",
      "  Downloading scipy-1.8.0-cp310-cp310-win_amd64.whl (37.0 MB)\n",
      "     ---------------------------------------- 37.0/37.0 MB 4.5 MB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\wequalwo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Using legacy 'setup.py install' for sklearn, since package 'wheel' is not installed.\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn, sklearn\n",
      "  Running setup.py install for sklearn: started\n",
      "  Running setup.py install for sklearn: finished with status 'done'\n",
      "Successfully installed scikit-learn-1.0.2 scipy-1.8.0 sklearn-0.0 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b43db559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "\n",
    "import re #регулярные выражения\n",
    "import math\n",
    "from collections import Counter\n",
    "import requests\n",
    "import time\n",
    "alphabet = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73fee5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BYTES_TO_MB_DIV = 0.000001\n",
    "def print_memory_usage_of_data_frame(df):\n",
    "    mem = round(df.memory_usage().sum() * BYTES_TO_MB_DIV, 3) \n",
    "    print(\"Memory usage is \" + str(mem) + \" MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70bf5d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\wequalwo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\wequalwo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords') # to use stopwords\n",
    "nltk.download('punkt') # to use word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15c9ebc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Это', 'простое', 'предложение', 'показывает', 'фильтрацию', 'на', 'стоп-слова']\n",
      "['Это', 'простое', 'предложение', 'показывает', 'фильтрацию', 'стоп-слова']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords as stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    " \n",
    "example_sent = \"\"\"Это простое предложение показывает фильтрацию на стоп-слова\"\"\"\n",
    " \n",
    "stop_words = set(stopwords.words('russian'))\n",
    " \n",
    "word_tokens = word_tokenize(example_sent)\n",
    " \n",
    "filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    " \n",
    "filtered_sentence = []\n",
    " \n",
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    " \n",
    "print(word_tokens)\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2863a1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['и',\n",
       " 'в',\n",
       " 'во',\n",
       " 'не',\n",
       " 'что',\n",
       " 'он',\n",
       " 'на',\n",
       " 'я',\n",
       " 'с',\n",
       " 'со',\n",
       " 'как',\n",
       " 'а',\n",
       " 'то',\n",
       " 'все',\n",
       " 'она',\n",
       " 'так',\n",
       " 'его',\n",
       " 'но',\n",
       " 'да',\n",
       " 'ты',\n",
       " 'к',\n",
       " 'у',\n",
       " 'же',\n",
       " 'вы',\n",
       " 'за',\n",
       " 'бы',\n",
       " 'по',\n",
       " 'только',\n",
       " 'ее',\n",
       " 'мне',\n",
       " 'было',\n",
       " 'вот',\n",
       " 'от',\n",
       " 'меня',\n",
       " 'еще',\n",
       " 'нет',\n",
       " 'о',\n",
       " 'из',\n",
       " 'ему',\n",
       " 'теперь',\n",
       " 'когда',\n",
       " 'даже',\n",
       " 'ну',\n",
       " 'вдруг',\n",
       " 'ли',\n",
       " 'если',\n",
       " 'уже',\n",
       " 'или',\n",
       " 'ни',\n",
       " 'быть',\n",
       " 'был',\n",
       " 'него',\n",
       " 'до',\n",
       " 'вас',\n",
       " 'нибудь',\n",
       " 'опять',\n",
       " 'уж',\n",
       " 'вам',\n",
       " 'ведь',\n",
       " 'там',\n",
       " 'потом',\n",
       " 'себя',\n",
       " 'ничего',\n",
       " 'ей',\n",
       " 'может',\n",
       " 'они',\n",
       " 'тут',\n",
       " 'где',\n",
       " 'есть',\n",
       " 'надо',\n",
       " 'ней',\n",
       " 'для',\n",
       " 'мы',\n",
       " 'тебя',\n",
       " 'их',\n",
       " 'чем',\n",
       " 'была',\n",
       " 'сам',\n",
       " 'чтоб',\n",
       " 'без',\n",
       " 'будто',\n",
       " 'чего',\n",
       " 'раз',\n",
       " 'тоже',\n",
       " 'себе',\n",
       " 'под',\n",
       " 'будет',\n",
       " 'ж',\n",
       " 'тогда',\n",
       " 'кто',\n",
       " 'этот',\n",
       " 'того',\n",
       " 'потому',\n",
       " 'этого',\n",
       " 'какой',\n",
       " 'совсем',\n",
       " 'ним',\n",
       " 'здесь',\n",
       " 'этом',\n",
       " 'один',\n",
       " 'почти',\n",
       " 'мой',\n",
       " 'тем',\n",
       " 'чтобы',\n",
       " 'нее',\n",
       " 'сейчас',\n",
       " 'были',\n",
       " 'куда',\n",
       " 'зачем',\n",
       " 'всех',\n",
       " 'никогда',\n",
       " 'можно',\n",
       " 'при',\n",
       " 'наконец',\n",
       " 'два',\n",
       " 'об',\n",
       " 'другой',\n",
       " 'хоть',\n",
       " 'после',\n",
       " 'над',\n",
       " 'больше',\n",
       " 'тот',\n",
       " 'через',\n",
       " 'эти',\n",
       " 'нас',\n",
       " 'про',\n",
       " 'всего',\n",
       " 'них',\n",
       " 'какая',\n",
       " 'много',\n",
       " 'разве',\n",
       " 'три',\n",
       " 'эту',\n",
       " 'моя',\n",
       " 'впрочем',\n",
       " 'хорошо',\n",
       " 'свою',\n",
       " 'этой',\n",
       " 'перед',\n",
       " 'иногда',\n",
       " 'лучше',\n",
       " 'чуть',\n",
       " 'том',\n",
       " 'нельзя',\n",
       " 'такой',\n",
       " 'им',\n",
       " 'более',\n",
       " 'всегда',\n",
       " 'конечно',\n",
       " 'всю',\n",
       " 'между']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbeb98bc",
   "metadata": {},
   "source": [
    "**Создадим функции, позволяющие генерировать следующие ошибки в словах:**\n",
    "\n",
    "1.   **Пропуск буквы:** ${резонанс - рзонанс}$\n",
    "2.   **Дублирование буквы:** ${резонанс - реезонанс}$\n",
    "3.   **Перестановка букв:** ${резонанс - рзеонанс}$\n",
    "4.   **Опечатка:** ${резонанс - ркзонанс}$\n",
    "5.   **Некоторые орфографические ошибки:**  ${резонанс - ризонанс}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92be3754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# все ошибки на расстоянии 2 (расстояние Левинштейна)\n",
    "def distance2(word):\n",
    "  return {e2 for e1 in distance1(word) if e1 for e2 in distance1(e1)}\n",
    "\n",
    "# все ошибки на расстоянии 1 (расстояние Левинштейна)\n",
    "def distance1(word):\n",
    "    pairs      = splits(word)\n",
    "    transposes = [a+b[1]+b[0]+b[2:]  for (a,b) in pairs if len(b)>1]                           # перестановки\n",
    "    replaces   = [a+c+b[1:]          for (a,b) in pairs if b for c in replaces_set[b[0]] if b] # замены: \n",
    "                                                                                                        # опечатки, \n",
    "                                                                                                        # пропуски и дублирования букв, \n",
    "                                                                                                        # орфографические ошибки\n",
    "\n",
    "    last_replaces = [word[0:-1] + c for c in replaces_set[word[-1]]]                           # замены в конце слова\n",
    "    return set(transposes + replaces + last_replaces)\n",
    "\n",
    "def splits(word):\n",
    "    return [(word[:i], word[i:])\n",
    "            for i in range (len(word)+1)]\n",
    "\n",
    "# список возможных замен в слове 'с', 'в', 'у', 'к', 'е', 'п', 'м', 'о', 'aa', ''\n",
    "replaces_set = pd.Series([          \n",
    "               ['с', 'в', 'у', 'к', 'е', 'п', 'м', 'о', 'аа', ''],\n",
    "               ['ь', 'о', 'л', 'д', 'ж', 'ю', 'п', 'бб', ''],\n",
    "               ['ч', 'ы', 'ц', 'у', 'к', 'а', 'с', 'вв', 'ф', ''],\n",
    "               ['р', 'н', 'ш', 'л', 'о', 'гг', 'к', ''],\n",
    "               ['б', 'л', 'ш', 'щ', 'з', 'ж', 'ю', 'дд', 'т', ''],\n",
    "               ['а', 'к', 'н', 'р', 'п', 'ее', 'и', 'ё', 'о', ''],\n",
    "               ['ёё', 'й', 'йо', 'е', ''],\n",
    "               ['ю', 'д', 'щ', 'з', 'х', 'э', 'жж', 'ш', ''],\n",
    "               ['д', 'щ', 'х', 'э', 'ж', 'зз', 'с', ''],\n",
    "               ['м', 'а', 'п', 'р', 'т', 'ии', 'е', 'ы', ''],\n",
    "               ['ц', 'ы', 'ф', 'йй',''],\n",
    "               ['а', 'в', 'у', 'е', 'п', 'п', 'а', 'кк', 'г', ''],\n",
    "               ['ь', 'о', 'г', 'ш', 'щ', 'д', 'б', 'лл', ''],\n",
    "               ['с', 'а', 'п', 'и', 'мм', 'н', ''],\n",
    "               ['р', 'п', 'е', 'г', 'о', 'нн', 'м', ''],\n",
    "               ['т', 'р', 'н', 'г', 'ш', 'л', 'ь', 'оо', 'а', 'е', 'ё', 'у', ''],\n",
    "               ['м', 'а', 'к', 'е', 'н', 'р', 'и', 'пп', 'б', ''],\n",
    "               ['и', 'п', 'е', 'н', 'г', 'о', 'т', 'рр', 'р', ''],\n",
    "               ['ч', 'в', 'а', 'м', 'сс', 'з', ''],\n",
    "               ['и', 'п', 'р', 'о', 'ь', 'тт', 'д', ''],\n",
    "               ['в', 'ы', 'ц', 'к', 'а', 'уу', 'ю', 'о', ''],\n",
    "               ['я', 'ч', 'ы', 'ц', 'й', 'фф', 'в', ''],\n",
    "               ['ж', 'з', 'ъ', 'э', 'хх', ''],\n",
    "               ['ы', 'ф', 'й', 'у', 'в', 'ы', 'цц', 'ч', ''],\n",
    "               ['я', 'ф', 'ы', 'в', 'с', 'чч', ''],\n",
    "               ['л', 'о', 'г', 'щ', 'д', 'шш', 'щ', 'шь', 'щь', 'ж', ''],\n",
    "               ['л', 'ш', 'з', 'ж', 'д', 'щщ', 'щь', 'шь', 'ж', ''],\n",
    "               ['э', 'х', 'ъъ', 'ь', ''],\n",
    "               ['ч', 'я', 'ф', 'й', 'ц', 'у', 'в', 'и', 'ыы', ''],\n",
    "               ['т', 'о', 'л', 'б', 'ьь', 'ъ', ''],\n",
    "               ['ж', 'з', 'х', 'ъ', ''],\n",
    "               ['б', 'л', 'д', 'ж', 'э', 'у', 'йу', ''],\n",
    "               ['ф', 'ы', 'ч', 'яя', 'а', 'йа', ''],\n",
    "               ], \n",
    "               index = ['а','б','в','г', 'д', 'е', 'ё', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2a202440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "with codecs.open('top10000.txt', 'r', encoding='utf-8') as file:\n",
    "    TEXT = file.read().replace('\\n', ' ')\n",
    "\n",
    "\n",
    "def tokens(text):\n",
    "    return re.findall(r'[а-я]+', text.lower())\n",
    "list_of_words = tokens(TEXT)\n",
    "\n",
    "# удалим все слова, короче 3 символов (потому что слова из 2х символов неинформативны):\n",
    "tmp = [w for w in list_of_words if len(w) > 2]\n",
    "list_of_words = tmp\n",
    "\n",
    "del list_of_words[500:]\n",
    "\n",
    "#print(list_of_words)\n",
    "print(len(list_of_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "94ac577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for item in list_of_words:\n",
    "  words.append([item, distance1(item).union(distance2(item))])# ??? как оптимизировать - неясно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "30543a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'пп рр ии вв ее тт'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _tokenize(word):\n",
    "  return \" \".join([a + a for a in word])\n",
    "_tokenize('привет')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "30417508",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = []\n",
    "to_vec = []\n",
    "for w in words:\n",
    "  tokens = []\n",
    "  for errors in w[1]:\n",
    "    st = _tokenize(errors)\n",
    "    tokens.append(st)\n",
    "    to_vec.append(st)\n",
    "  tokenized.append([w[0], tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1d5ab93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(to_vec[400:450])\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = to_vec\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d430b1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['аа', 'бб', 'вв', 'гг', 'дд', 'ее', 'жж', 'зз', 'ии', 'йй', 'кк',\n",
       "       'лл', 'мм', 'нн', 'оо', 'пп', 'рр', 'сс', 'тт', 'уу', 'фф', 'хх',\n",
       "       'цц', 'чч', 'шш', 'щщ', 'ъъ', 'ыы', 'ьь', 'ээ', 'юю', 'яя', 'ёё'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# найденные токены:\n",
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "27721f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4aa667d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "_words = []\n",
    "for i in range(0, len(tokenized)):\n",
    "  for j in range(0, len(tokenized[i][1])):\n",
    "    labels.append(i)\n",
    "    _words.append(tokenized[i][0])\n",
    "df[\"label\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "28b1ee9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.751400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.617764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.736919</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.273837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.369858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884053</th>\n",
       "      <td>0.251631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.281763</td>\n",
       "      <td>0.352994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.395686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884054</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.212751</td>\n",
       "      <td>0.266535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.298770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884055</th>\n",
       "      <td>0.269069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.329834</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.377457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.423107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884056</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.650069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.296906</td>\n",
       "      <td>0.371965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884057</th>\n",
       "      <td>0.259888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.318580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.291010</td>\n",
       "      <td>0.364578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>884058 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0    1         2    3    4    5    6    7         8         9  \\\n",
       "0       0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000   \n",
       "1       0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000   \n",
       "2       0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000   \n",
       "3       0.273837  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000   \n",
       "4       0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000   \n",
       "...          ...  ...       ...  ...  ...  ...  ...  ...       ...       ...   \n",
       "884053  0.251631  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.281763  0.352994   \n",
       "884054  0.000000  0.0  0.232907  0.0  0.0  0.0  0.0  0.0  0.212751  0.266535   \n",
       "884055  0.269069  0.0  0.329834  0.0  0.0  0.0  0.0  0.0  0.000000  0.377457   \n",
       "884056  0.000000  0.0  0.650069  0.0  0.0  0.0  0.0  0.0  0.296906  0.371965   \n",
       "884057  0.259888  0.0  0.318580  0.0  0.0  0.0  0.0  0.0  0.291010  0.364578   \n",
       "\n",
       "        ...   24   25   26        27        28   29   30   31        32  label  \n",
       "0       ...  0.0  0.0  0.0  0.000000  0.751400  0.0  0.0  0.0  0.000000      0  \n",
       "1       ...  0.0  0.0  0.0  0.617764  0.000000  0.0  0.0  0.0  0.000000      0  \n",
       "2       ...  0.0  0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.736919      0  \n",
       "3       ...  0.0  0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.000000      0  \n",
       "4       ...  0.0  0.0  0.0  0.000000  0.369858  0.0  0.0  0.0  0.000000      0  \n",
       "...     ...  ...  ...  ...       ...       ...  ...  ...  ...       ...    ...  \n",
       "884053  ...  0.0  0.0  0.0  0.395686  0.000000  0.0  0.0  0.0  0.000000    499  \n",
       "884054  ...  0.0  0.0  0.0  0.298770  0.000000  0.0  0.0  0.0  0.000000    499  \n",
       "884055  ...  0.0  0.0  0.0  0.423107  0.000000  0.0  0.0  0.0  0.000000    499  \n",
       "884056  ...  0.0  0.0  0.0  0.416951  0.000000  0.0  0.0  0.0  0.000000    499  \n",
       "884057  ...  0.0  0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.000000    499  \n",
       "\n",
       "[884058 rows x 34 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6844b43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics  import f1_score, accuracy_score\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2aee9fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we split our data into input and output\n",
    "# y is the output and is stored in \"Class\" column of dataframe\n",
    "# X contains the other columns and are features or input\n",
    "# train = df\n",
    "# y = train.label\n",
    "# train.drop(['label'], axis = 1, inplace=True)\n",
    "# X = train\n",
    "# Now we split the dataset in train and test part\n",
    "# here the train set is 75% and test set is 25%\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7f302ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CL = DecisionTreeClassifier()\n",
    "# CL.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "faa8aaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = CL.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0a91326e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Sparse[float64, nan]\n",
       "1        Sparse[float64, nan]\n",
       "2        Sparse[float64, nan]\n",
       "3        Sparse[float64, nan]\n",
       "4        Sparse[float64, nan]\n",
       "5        Sparse[float64, nan]\n",
       "6        Sparse[float64, nan]\n",
       "7        Sparse[float64, nan]\n",
       "8        Sparse[float64, nan]\n",
       "9        Sparse[float64, nan]\n",
       "10       Sparse[float64, nan]\n",
       "11       Sparse[float64, nan]\n",
       "12       Sparse[float64, nan]\n",
       "13       Sparse[float64, nan]\n",
       "14       Sparse[float64, nan]\n",
       "15       Sparse[float64, nan]\n",
       "16       Sparse[float64, nan]\n",
       "17       Sparse[float64, nan]\n",
       "18       Sparse[float64, nan]\n",
       "19       Sparse[float64, nan]\n",
       "20       Sparse[float64, nan]\n",
       "21       Sparse[float64, nan]\n",
       "22       Sparse[float64, nan]\n",
       "23       Sparse[float64, nan]\n",
       "24       Sparse[float64, nan]\n",
       "25       Sparse[float64, nan]\n",
       "26       Sparse[float64, nan]\n",
       "27       Sparse[float64, nan]\n",
       "28       Sparse[float64, nan]\n",
       "29       Sparse[float64, nan]\n",
       "30       Sparse[float64, nan]\n",
       "31       Sparse[float64, nan]\n",
       "32       Sparse[float64, nan]\n",
       "label                   int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert_to_sparse_pandas(df, exclude_columns = []):\n",
    "    df = df.copy()\n",
    "    exclude_columns = set(exclude_columns)\n",
    "\n",
    "    for (columnName, columnData) in df.iteritems():\n",
    "        if columnName in exclude_columns:\n",
    "            continue\n",
    "        df[columnName] = pd.arrays.SparseArray(columnData.values)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_sparse = convert_to_sparse_pandas(df, exclude_columns = [\"label\"])\n",
    "display(df_sparse.dtypes)\n",
    "# print_memory_usage_of_data_frame(data_one_hot_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b5a7bdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage is 233.391 MB\n",
      "Memory usage is 350.087 MB\n"
     ]
    }
   ],
   "source": [
    "y = df['label']\n",
    "X = df[df.columns.difference(['label'])]\n",
    "y_sparse = df_sparse['label']\n",
    "X_sparse = df_sparse[df_sparse.columns.difference(['label'])]\n",
    "print_memory_usage_of_data_frame(X)\n",
    "print_memory_usage_of_data_frame(X_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d0052483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "def data_frame_to_scipy_sparse_matrix(df):\n",
    "    arr = lil_matrix(df.shape, dtype = np.float32)\n",
    "    for i, col in enumerate(df.columns):\n",
    "        ix = df[col] != 0\n",
    "        arr[np.where(ix), i] = 1\n",
    "    return arr.tocsr()\n",
    "\n",
    "def get_csr_memory_usage(matrix):\n",
    "    mem = (X_csr.data.nbytes + X_csr.indptr.nbytes + X_csr.indices.nbytes) * BYTES_TO_MB_DIV\n",
    "    print(\"Memory usage is \" + str(mem) + \" MB\")\n",
    "    \n",
    "y_csr = y_sparse\n",
    "X_csr = data_frame_to_scipy_sparse_matrix(X_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "03afc512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "Memory usage is 233.391 MB\n",
      "X_sparse:\n",
      "Memory usage is 350.087 MB\n",
      "X_csr:\n",
      "Memory usage is 46.89978 MB\n"
     ]
    }
   ],
   "source": [
    "print('X:')\n",
    "print_memory_usage_of_data_frame(X)\n",
    "print('X_sparse:')\n",
    "print_memory_usage_of_data_frame(X_sparse)\n",
    "print('X_csr:')\n",
    "get_csr_memory_usage(X_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e2ab54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-test split: 0.24 secs\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "\n",
    "vector_dict = {'Pandas dataframe': [X,y],\n",
    "    'Sparse pandas dataframe': [X_sparse, y_sparse],\n",
    "    'Scipy sparse matrix': [X_csr, y_csr]\n",
    "    }\n",
    "\n",
    "start = time.time()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_csr, y_csr, test_size = 0.3, random_state = 42)\n",
    "end = time.time()\n",
    "\n",
    "duration = round(end - start, 2)\n",
    "print(\"Train-test split: \" + str(duration) + \" secs\")\n",
    "\n",
    "start = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "duration = round(end - start, 2)\n",
    "print(\"Training: \" + str(duration) + \" secs\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "013b7b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 55.93 secs\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "pred = model.predict(X_test)\n",
    "end = time.time()\n",
    "duration = round(end - start, 2)\n",
    "print(\"Testing: \" + str(duration) + \" secs\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1f39336a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013475827849223401\n",
      "0.013475827849223401\n",
      "3471.845461988808\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print(accuracy_score(y_test, pred))\n",
    "print(f1_score(y_test, pred, average = 'micro'))\n",
    " \n",
    "print(mean_absolute_error(y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
